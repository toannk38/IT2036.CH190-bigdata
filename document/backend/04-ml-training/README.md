# ML Training Documentation

## Overview

The ML Training layer handles the complete machine learning pipeline from data preparation to model deployment. It supports multiple model types including ARIMA, LSTM, Transformers, and CatBoost for stock price prediction and technical analysis.

**Status**: ğŸ”„ **PLANNED**

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   MongoDB       â”‚â”€â”€â”€â–ºâ”‚ Data Preparation â”‚â”€â”€â”€â–ºâ”‚ Feature Store   â”‚
â”‚ (Raw Price Data)â”‚    â”‚   & Engineering  â”‚    â”‚   (Features)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚                       â”‚
                                â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Experiments   â”‚â—„â”€â”€â”€â”‚ Model Training   â”‚â—„â”€â”€â”€â”‚ Model Registry  â”‚
â”‚  (Notebooks)    â”‚    â”‚   & Tuning       â”‚    â”‚  (Artifacts)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Research      â”‚    â”‚ Model Evaluation â”‚    â”‚   Production    â”‚
â”‚   & Analysis    â”‚    â”‚  & Backtesting   â”‚    â”‚   Deployment    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Directory Structure

```
ml-training/
â”œâ”€â”€ data-preparation/           # Feature engineering & data cleaning
â”‚   â”œâ”€â”€ feature_engineering.py  # Technical indicators, patterns
â”‚   â”œâ”€â”€ data_cleaning.py        # Data validation, outlier removal
â”‚   â”œâ”€â”€ data_loader.py          # Load data from MongoDB
â”‚   â”œâ”€â”€ feature_selection.py    # Feature importance analysis
â”‚   â”œâ”€â”€ data_splitter.py        # Train/test/validation split
â”‚   â”œâ”€â”€ preprocessors/
â”‚   â”‚   â”œâ”€â”€ price_preprocessor.py
â”‚   â”‚   â”œâ”€â”€ volume_preprocessor.py
â”‚   â”‚   â””â”€â”€ news_preprocessor.py
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ feature_config.yml
â”œâ”€â”€ model-training/             # Training scripts
â”‚   â”œâ”€â”€ arima/
â”‚   â”‚   â”œâ”€â”€ train_arima.py
â”‚   â”‚   â”œâ”€â”€ hyperparameter_tuning.py
â”‚   â”‚   â””â”€â”€ config/arima_config.yml
â”‚   â”œâ”€â”€ lstm/
â”‚   â”‚   â”œâ”€â”€ train_lstm.py
â”‚   â”‚   â”œâ”€â”€ model_architecture.py
â”‚   â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”‚   â””â”€â”€ config/lstm_config.yml
â”‚   â”œâ”€â”€ transformer/
â”‚   â”‚   â”œâ”€â”€ train_transformer.py
â”‚   â”‚   â”œâ”€â”€ attention_model.py
â”‚   â”‚   â”œâ”€â”€ positional_encoding.py
â”‚   â”‚   â””â”€â”€ config/transformer_config.yml
â”‚   â”œâ”€â”€ catboost/
â”‚   â”‚   â”œâ”€â”€ train_catboost.py
â”‚   â”‚   â”œâ”€â”€ feature_importance.py
â”‚   â”‚   â””â”€â”€ config/catboost_config.yml
â”‚   â””â”€â”€ ensemble/
â”‚       â”œâ”€â”€ ensemble_trainer.py
â”‚       â”œâ”€â”€ model_stacking.py
â”‚       â””â”€â”€ voting_classifier.py
â”œâ”€â”€ model-evaluation/           # Backtesting & metrics
â”‚   â”œâ”€â”€ backtesting/
â”‚   â”‚   â”œâ”€â”€ backtest_engine.py
â”‚   â”‚   â”œâ”€â”€ strategy_tester.py
â”‚   â”‚   â””â”€â”€ performance_analyzer.py
â”‚   â”œâ”€â”€ metrics/
â”‚   â”‚   â”œâ”€â”€ regression_metrics.py
â”‚   â”‚   â”œâ”€â”€ classification_metrics.py
â”‚   â”‚   â”œâ”€â”€ trading_metrics.py
â”‚   â”‚   â””â”€â”€ risk_metrics.py
â”‚   â”œâ”€â”€ validation/
â”‚   â”‚   â”œâ”€â”€ cross_validator.py
â”‚   â”‚   â”œâ”€â”€ time_series_validator.py
â”‚   â”‚   â””â”€â”€ walk_forward_validator.py
â”‚   â””â”€â”€ reports/
â”‚       â”œâ”€â”€ model_report_generator.py
â”‚       â”œâ”€â”€ performance_dashboard.py
â”‚       â””â”€â”€ comparison_report.py
â”œâ”€â”€ experiments/                # Research & notebooks
â”‚   â”œâ”€â”€ notebooks/
â”‚   â”‚   â”œâ”€â”€ data_exploration.ipynb
â”‚   â”‚   â”œâ”€â”€ feature_analysis.ipynb
â”‚   â”‚   â”œâ”€â”€ model_comparison.ipynb
â”‚   â”‚   â””â”€â”€ strategy_research.ipynb
â”‚   â”œâ”€â”€ research/
â”‚   â”‚   â”œâ”€â”€ market_regime_detection.py
â”‚   â”‚   â”œâ”€â”€ volatility_modeling.py
â”‚   â”‚   â””â”€â”€ correlation_analysis.py
â”‚   â””â”€â”€ prototypes/
â”‚       â”œâ”€â”€ new_indicators.py
â”‚       â”œâ”€â”€ alternative_models.py
â”‚       â””â”€â”€ ensemble_experiments.py
â””â”€â”€ pipelines/                  # Training pipelines
    â”œâ”€â”€ training_pipeline.py    # Main training orchestrator
    â”œâ”€â”€ data_pipeline.py        # Data processing pipeline
    â”œâ”€â”€ model_pipeline.py       # Model training pipeline
    â”œâ”€â”€ evaluation_pipeline.py  # Evaluation pipeline
    â”œâ”€â”€ deployment_pipeline.py  # Model deployment pipeline
    â”œâ”€â”€ schedulers/
    â”‚   â”œâ”€â”€ daily_retrain.py
    â”‚   â”œâ”€â”€ weekly_evaluation.py
    â”‚   â””â”€â”€ monthly_backtest.py
    â””â”€â”€ config/
        â””â”€â”€ pipeline_config.yml
```

## Configuration

### Environment Variables
```python
# Data Configuration
MONGODB_URI=mongodb://localhost:27017
MONGODB_DATABASE=stock_ai
FEATURE_STORE_PATH=/app/features
MODEL_REGISTRY_PATH=/app/models

# Training Configuration
TRAINING_DATA_DAYS=1000
VALIDATION_SPLIT=0.2
TEST_SPLIT=0.1
RANDOM_SEED=42

# Model Configuration
ARIMA_MAX_ORDER=(5,1,5)
LSTM_SEQUENCE_LENGTH=60
TRANSFORMER_D_MODEL=512
CATBOOST_ITERATIONS=1000

# Compute Configuration
USE_GPU=true
N_JOBS=4
BATCH_SIZE=32
```

## Model Types

### 1. ARIMA Models
**Purpose**: Time series forecasting with trend and seasonality
**Features**:
- Auto-ARIMA for order selection
- Seasonal decomposition
- Residual analysis
- Confidence intervals

### 2. LSTM Models
**Purpose**: Deep learning for sequential pattern recognition
**Features**:
- Multi-layer LSTM architecture
- Dropout regularization
- Attention mechanisms
- Bidirectional processing

### 3. Transformer Models
**Purpose**: Attention-based sequence modeling
**Features**:
- Multi-head attention
- Positional encoding
- Layer normalization
- Residual connections

### 4. CatBoost Models
**Purpose**: Gradient boosting for feature-rich predictions
**Features**:
- Categorical feature handling
- Feature importance analysis
- Cross-validation
- Hyperparameter optimization

### 5. Ensemble Models
**Purpose**: Combining multiple models for better performance
**Features**:
- Voting classifiers
- Model stacking
- Dynamic weighting
- Confidence-based selection

## Feature Engineering

### Technical Indicators
```python
# Price-based features
- Returns (1d, 5d, 20d)
- Volatility (rolling std)
- Price ratios (high/low, close/open)

# Technical indicators
- RSI (14, 30 periods)
- MACD (12, 26, 9)
- Bollinger Bands (20, 2)
- Moving Averages (5, 10, 20, 50, 200)
- Stochastic Oscillator
- Williams %R
- ATR (Average True Range)

# Volume indicators
- Volume SMA
- Volume Rate of Change
- On-Balance Volume (OBV)
- Volume Price Trend (VPT)

# Pattern features
- Candlestick patterns (doji, hammer, etc.)
- Support/resistance levels
- Trend lines
- Chart patterns
```

## Evaluation Metrics

### Regression Metrics
- **MAE**: Mean Absolute Error
- **RMSE**: Root Mean Square Error
- **MAPE**: Mean Absolute Percentage Error
- **RÂ²**: Coefficient of Determination
- **Directional Accuracy**: Prediction direction correctness

### Trading Metrics
- **Sharpe Ratio**: Risk-adjusted returns
- **Maximum Drawdown**: Largest peak-to-trough decline
- **Win Rate**: Percentage of profitable trades
- **Profit Factor**: Gross profit / Gross loss
- **Calmar Ratio**: Annual return / Maximum drawdown

## Tools and Technologies

### Core Libraries
- **pandas**: Data manipulation
- **numpy**: Numerical computing
- **scikit-learn**: Machine learning
- **tensorflow/keras**: Deep learning
- **catboost**: Gradient boosting
- **statsmodels**: Statistical models

### Specialized Libraries
- **ta-lib**: Technical analysis
- **arch**: GARCH models
- **pmdarima**: Auto-ARIMA
- **optuna**: Hyperparameter optimization
- **mlflow**: Experiment tracking